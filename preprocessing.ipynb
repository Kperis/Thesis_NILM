{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting Korean data\n"
     ]
    }
   ],
   "source": [
    "#extract korean dataset\n",
    "from load_korean_data import extract_zips\n",
    "\n",
    "extract_zips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Room</th>\n",
       "      <th>CO2[ppm]</th>\n",
       "      <th>PM4[ug/m3]</th>\n",
       "      <th>Lighting[lux]</th>\n",
       "      <th>T_in[¬∞C]</th>\n",
       "      <th>RH [%]</th>\n",
       "      <th>PM10[ug/m3]</th>\n",
       "      <th>PM2_5[ug/m3]</th>\n",
       "      <th>PM1[ug/m3]</th>\n",
       "      <th>PM0_5[ug/m3]</th>\n",
       "      <th>T_out [¬∞C]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01 00:00:00</td>\n",
       "      <td>E145</td>\n",
       "      <td>624.23</td>\n",
       "      <td>65.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.46</td>\n",
       "      <td>55.51</td>\n",
       "      <td>65.44</td>\n",
       "      <td>65.42</td>\n",
       "      <td>65.22</td>\n",
       "      <td>56.81</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01 01:00:00</td>\n",
       "      <td>E145</td>\n",
       "      <td>629.00</td>\n",
       "      <td>66.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.48</td>\n",
       "      <td>56.39</td>\n",
       "      <td>66.78</td>\n",
       "      <td>66.76</td>\n",
       "      <td>66.56</td>\n",
       "      <td>57.97</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01 02:00:00</td>\n",
       "      <td>E145</td>\n",
       "      <td>640.13</td>\n",
       "      <td>67.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.45</td>\n",
       "      <td>56.74</td>\n",
       "      <td>67.79</td>\n",
       "      <td>67.77</td>\n",
       "      <td>67.57</td>\n",
       "      <td>58.85</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01 03:00:00</td>\n",
       "      <td>E145</td>\n",
       "      <td>639.77</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.39</td>\n",
       "      <td>57.08</td>\n",
       "      <td>68.01</td>\n",
       "      <td>67.98</td>\n",
       "      <td>67.78</td>\n",
       "      <td>59.04</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01 04:00:00</td>\n",
       "      <td>E145</td>\n",
       "      <td>643.31</td>\n",
       "      <td>67.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>28.35</td>\n",
       "      <td>57.57</td>\n",
       "      <td>67.26</td>\n",
       "      <td>67.24</td>\n",
       "      <td>67.04</td>\n",
       "      <td>58.39</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Room  CO2[ppm]  PM4[ug/m3]  Lighting[lux]  T_in[¬∞C]  \\\n",
       "0  2024-07-01 00:00:00  E145    624.23       65.43           0.00     28.46   \n",
       "1  2024-07-01 01:00:00  E145    629.00       66.77           0.00     28.48   \n",
       "2  2024-07-01 02:00:00  E145    640.13       67.78           0.00     28.45   \n",
       "3  2024-07-01 03:00:00  E145    639.77       68.00           0.00     28.39   \n",
       "4  2024-07-01 04:00:00  E145    643.31       67.25           0.03     28.35   \n",
       "\n",
       "   RH [%]  PM10[ug/m3]  PM2_5[ug/m3]  PM1[ug/m3]  PM0_5[ug/m3]  T_out [¬∞C]  \n",
       "0   55.51        65.44         65.42       65.22         56.81        24.5  \n",
       "1   56.39        66.78         66.76       66.56         57.97        24.0  \n",
       "2   56.74        67.79         67.77       67.57         58.85        22.3  \n",
       "3   57.08        68.01         67.98       67.78         59.04        22.0  \n",
       "4   57.57        67.26         67.24       67.04         58.39        21.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_madalena_comfort = pd.read_csv('datasets/madalena_comfort.csv')\n",
    "\n",
    "df_madalena_comfort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def load_house_data(house_path):\n",
    "    appliance_df_list = [] \n",
    "    total_load_df = None  \n",
    "    sub_folders = [d for d in os.listdir(house_path) if os.path.isdir(os.path.join(house_path, d))]\n",
    "\n",
    "    if not sub_folders:\n",
    "        print(f\"‚ö†Ô∏è No sub-folder found in {house_path}\")\n",
    "        return None\n",
    "    house_sub_folder = os.path.join(house_path, sub_folders[0])\n",
    "    for timestamp_folder in sorted(os.listdir(house_sub_folder)):\n",
    "        full_timestamp_path = os.path.join(house_sub_folder, timestamp_folder)\n",
    "\n",
    "        if os.path.isdir(full_timestamp_path):\n",
    "            for file in glob(os.path.join(full_timestamp_path, \"*.parquet.gzip\")):\n",
    "                appliance_name = os.path.basename(file).replace(\".parquet.gzip\", \"\")\n",
    "\n",
    "                df = pd.read_parquet(file)\n",
    "                df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"] / 1000, unit=\"s\")  \n",
    "                df[\"appliance\"] = appliance_name  \n",
    "\n",
    "                if \"total\" in appliance_name: \n",
    "                    total_load_df = df\n",
    "                else:\n",
    "                    appliance_df_list.append(df)\n",
    "\n",
    "    if appliance_df_list:\n",
    "        appliance_df = pd.concat(appliance_df_list, ignore_index=True)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if total_load_df is not None:\n",
    "        appliance_df = appliance_df.merge(total_load_df, on=\"timestamp\", suffixes=(\"\", \"_total\"))\n",
    "\n",
    "    return appliance_df\n",
    "\n",
    "def process_house(house_id):\n",
    "    house_path = os.path.join(\"datasets/korean_extracted\", house_id)\n",
    "\n",
    "    if os.path.isdir(house_path):\n",
    "        print(f\"üîÑ Processing {house_id}...\")\n",
    "        return house_id, load_house_data(house_path)\n",
    "\n",
    "    return house_id, None\n",
    "\n",
    "def process_all_houses():\n",
    "    extracted_data_dir = \"datasets/korean_extracted\"\n",
    "    houses = [d for d in os.listdir(extracted_data_dir) if os.path.isdir(os.path.join(extracted_data_dir, d))]\n",
    "\n",
    "    with Pool(processes=4) as pool:  # Adjust based on CPU cores\n",
    "        results = pool.map(process_house, houses)\n",
    "\n",
    "    all_houses_data = {house_id: df for house_id, df in results if df is not None}\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(all_houses_data)} houses' data in parallel!\")\n",
    "    return all_houses_data\n",
    "extracted_korean_path = 'datasets/korean_extracted'\n",
    "all_houses_data = {}\n",
    "\n",
    "def resample_to_5Hz(df):\n",
    "    df = df.set_index(\"timestamp\")  # Ensure timestamp is the index\n",
    "    df_5Hz = df.resample(\"200ms\").mean().reset_index()  # 5Hz resampling\n",
    "    return df_5Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_dataset():\n",
    "    all_houses_data = process_all_houses()\n",
    "\n",
    "    for house_id, df in all_houses_data.items():\n",
    "        df_5Hz = resample_to_5Hz(df)\n",
    "        df_5Hz.to_parquet(f\"datasets/processed_data/{house_id}_5Hz.parquet\", compression=\"gzip\")\n",
    "        print(f\"üìÅ Saved downsampled data for {house_id}\")\n",
    "\n",
    "    # Merge all houses into a final dataset\n",
    "    # final_dataset = pd.concat([resample_to_5Hz(df) for df in all_houses_data.values()], ignore_index=True)\n",
    "    # final_dataset.to_parquet(\"final_microgrid_5Hz.parquet\", compression=\"gzip\")\n",
    "\n",
    "    # print(\"‚úÖ Final dataset created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_final_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
